{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969732eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e277e69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2d(img):\n",
    "    global img_1d\n",
    "    img_1d = img.flatten()\n",
    "    return img_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c2c441",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder_selected = 'D:/Essential Things/Work/Thesis/Files/New folder'\n",
    "data_files = [(x[0], x[2]) for x in os.walk(test_folder_selected)]\n",
    "test_images = []\n",
    "d = []\n",
    "i = 0\n",
    "for filename in os.listdir(test_folder_selected):\n",
    "    if os.path.splitext(os.path.basename(data_files[0][1][i]))[1] == '.pgm':\n",
    "        img = cv2.imread(os.path.join(test_folder_selected,filename),-1)\n",
    "        if img is not None:\n",
    "            test_images.append(img)\n",
    "    else:\n",
    "        img = cv2.imread(os.path.join(test_folder_selected,filename),cv2.IMREAD_UNCHANGED)\n",
    "        if img is not None:\n",
    "            test_images.append(img)\n",
    "    \n",
    "    img = test_images[i].flatten()\n",
    "    print(img)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e713e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for image in test_images:\n",
    "    test_images[i]\n",
    "    channels = test_images[i].shape\n",
    "    #print(test_images[i])\n",
    "    #height, width, channels = test_images[i].shape\n",
    "    #print (height, width, channels)\n",
    "    #print(os.path.splitext(os.path.basename(data_files[0][1][i]))[1])\n",
    "    i += 1\n",
    "\n",
    "#imgplot = plt.imshow(test_images[2])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0e6627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading in modules\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import sqlalchemy \n",
    "\n",
    "# creating file path\n",
    "dbfile = 'C:/Users/mm_pa/Documents/Face Recognition/Train_Images.db'\n",
    "# Create a SQL connection to our SQLite database\n",
    "con = sqlite3.connect(dbfile)\n",
    "\n",
    "# creating cursor\n",
    "cur = con.cursor()\n",
    "\n",
    "# reading all table names\n",
    "table_list = [a for a in cur.execute(\"SELECT name FROM sqlite_master WHERE type = 'table'\")]\n",
    "# here is you table list\n",
    "print(table_list)\n",
    "print(f\"Table Name : {cur.fetchall()}\")\n",
    "\n",
    "df = pd.read_sql_query('SELECT * FROM train_images', con)\n",
    "print(df)\n",
    "# Be sure to close the connection\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25219a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageTk, Image\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "\n",
    "train_conn = sqlite3.connect('Train_Images.db')\n",
    "train_connection = train_conn.cursor()\n",
    "\n",
    "train_connection.execute(\"SELECT *,oid FROM train_images\")\n",
    "#fetchall fetchmany(any number) fetchone\n",
    "records = train_connection.fetchall()\n",
    "#loop thru results\n",
    "size = []\n",
    "\n",
    "for record in records:\n",
    "    row = int(re.findall(r'\\b\\d+\\b',record[2])[0])\n",
    "    column = int(re.findall(r'\\b\\d+\\b',record[2])[1])\n",
    "    image = record[5]\n",
    "    train_image_gray = record[6]\n",
    "    if train_image_gray == 1:\n",
    "        train_image_gray = image\n",
    "        \n",
    "    print(train_image_gray)\n",
    "train_conn.commit()\n",
    "train_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d41c87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageTk, Image\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "\n",
    "train_folder_selected = 'D:/Essential Things/Work/Thesis/Files/New folder'\n",
    "data_files = [(x[0], x[2]) for x in os.walk(train_folder_selected)]\n",
    "train_images = []\n",
    "i = 0\n",
    "for filename in os.listdir(train_folder_selected):\n",
    "        \n",
    "        #check if image format is .pgm read correctly or gray\n",
    "        if (os.path.splitext(os.path.basename(data_files[0][1][i]))[1] == '.pgm'):\n",
    "            img = cv2.imread(os.path.join(train_folder_selected,filename),-1)\n",
    "            if img is not None:\n",
    "                train_images.append(img)\n",
    "        else:\n",
    "            img = cv2.imread(os.path.join(train_folder_selected,filename),cv2.IMREAD_UNCHANGED)\n",
    "            if img is not None:\n",
    "                train_images.append(img)\n",
    "        \n",
    "        #convert image to 1 dimention\n",
    "        if (len(train_images[i].shape)<3):\n",
    "            img_1d_gray = train_images[i].flatten()\n",
    "        else:\n",
    "            \n",
    "            img_1d_gray = train_images[i].flatten()\n",
    "        img_1d = train_images[i].flatten()\n",
    "        print(train_images[i].shape)\n",
    "        #cv2.imshow('image window', train_images[i])\n",
    "        #cv2.waitKey(0)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6110ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import ImageTk, Image\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "\n",
    "train_images = []\n",
    "train_folder_selected = 'D:/Essential Things/Work/Thesis/Files/New folder'\n",
    "data_files = [(x[0], x[2]) for x in os.walk(train_folder_selected)]\n",
    "i = 0\n",
    "for filename in os.listdir(train_folder_selected):\n",
    "    if os.path.splitext(os.path.basename(data_files[0][1][i]))[1] == '.pgm':\n",
    "        img = cv2.imread(os.path.join(train_folder_selected,filename),-1)\n",
    "        if img is not None:\n",
    "            train_images.append(img)\n",
    "    else:\n",
    "        img = cv2.imread(os.path.join(train_folder_selected,filename),cv2.IMREAD_UNCHANGED)\n",
    "        if img is not None:\n",
    "            train_images.append(img)\n",
    "    \n",
    "\n",
    "    i += 1\n",
    "gray = cv2.cvtColor(train_images[0], cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('image window', gray)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb99a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CV2 be formate bgr mikhone axaro\n",
    "\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('D:/Essential Things/Work/Thesis/Files/New folder/1.1.jpg')\n",
    "\n",
    "# converte har bgr be formataye dg ke inja faghat kafie jaye hsv masalan image bezario bebini \n",
    "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "hsl = cv2.cvtColor(image, cv2.COLOR_BGR2HLS) # equal to HSL\n",
    "luv = cv2.cvtColor(image, cv2.COLOR_BGR2LUV)\n",
    "\n",
    "#converte bgr be gray\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "b = image.copy()\n",
    "# set green and red channels to 0\n",
    "b[:, :, 1] = 0\n",
    "b[:, :, 2] = 0\n",
    "\n",
    "\n",
    "g = image.copy()\n",
    "# set blue and red channels to 0\n",
    "g[:, :, 0] = 0\n",
    "g[:, :, 2] = 0\n",
    "\n",
    "r = image.copy()\n",
    "# set blue and green channels to 0\n",
    "r[:, :, 0] = 0\n",
    "r[:, :, 1] = 0\n",
    "\n",
    "\n",
    "# RGB - Blue\n",
    "cv2.imshow('B-RGB', b)\n",
    "\n",
    "# RGB - Green\n",
    "cv2.imshow('G-RGB', g)\n",
    "\n",
    "# RGB - Red\n",
    "cv2.imshow('R-RGB', r)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f48d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import re\n",
    "import os\n",
    "# uniform_map is a dictionary of 58 eigenvalues of equivalent pattern, which are serialized and numbered from small to large\n",
    "uniform_map = {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 6: 5, 7: 6, 8: 7, 12: 8,14: 9, 15: 10, 16: 11, 24: 12, 28: 13, 30: 14, 31: 15, 32: 16, 48: 17,\n",
    " 56: 18, 60: 19, 62: 20, 63: 21, 64: 22, 96: 23, 112: 24,120: 25, 124: 26, 126: 27, 127: 28, 128: 29, 129: 30, 131: 31, 135: 32,143: 33,\n",
    " 159: 34, 191: 35, 192: 36, 193: 37, 195: 38, 199: 39, 207: 40,223: 41, 224: 42, 225: 43, 227: 44, 231: 45, 239: 46, 240: 47, 241: 48,\n",
    "243: 49, 247: 50, 248: 51, 249: 52, 251: 53, 252: 54, 253: 55, 254: 56,255: 57}\n",
    "\n",
    "def cal_basic_lbp(img,i,j):#Points larger than the center pixel are assigned a value of 1, and those smaller than the center pixel are assigned a value of 0. The binary sequence is returned\n",
    "    sum = []\n",
    "    if img[i - 1, j ] > img[i, j]:\n",
    "        sum.append(1)\n",
    "    else:\n",
    "        sum.append(0)\n",
    "    if img[i - 1, j+1 ] > img[i, j]:\n",
    "        sum.append(1)\n",
    "    else:\n",
    "        sum.append(0)\n",
    "    if img[i , j + 1] > img[i, j]:\n",
    "        sum.append(1)\n",
    "    else:\n",
    "        sum.append(0)\n",
    "    if img[i + 1, j+1 ] > img[i, j]:\n",
    "        sum.append(1)\n",
    "    else:\n",
    "        sum.append(0)\n",
    "    if img[i + 1, j ] > img[i, j]:\n",
    "        sum.append(1)\n",
    "    else:\n",
    "        sum.append(0)\n",
    "    if img[i + 1, j - 1] > img[i, j]:\n",
    "        sum.append(1)\n",
    "    else:\n",
    "        sum.append(0)\n",
    "    if img[i , j - 1] > img[i, j]:\n",
    "        sum.append(1)\n",
    "    else:\n",
    "        sum.append(0)\n",
    "    if img[i - 1, j - 1] > img[i, j]:\n",
    "        sum.append(1)\n",
    "    else:\n",
    "        sum.append(0)\n",
    "    return sum    \n",
    "\n",
    "def bin_to_decimal(bin):#Binary to decimal\n",
    "    res = 0\n",
    "    bit_num = 0 #Shift left\n",
    "    for i in bin[::-1]:\n",
    "        res += i << bit_num   # Shifting n bits to the left is equal to multiplying by 2 to the nth power\n",
    "        bit_num += 1\n",
    "    return res\n",
    "\n",
    "    \n",
    "def lbp_uniform(img):\n",
    "    revolve_array = np.zeros(img.shape,np.uint8)\n",
    "    width = img.shape[0]\n",
    "    height = img.shape[1]\n",
    "    for i in range(1,width-1):\n",
    "        for j in range(1,height-1):\n",
    "            sum_ = cal_basic_lbp(img,i,j) #Get binary\n",
    "            num_ = calc_sum(sum_)  #Get jump times\n",
    "            if num_ <= 2:\n",
    "                revolve_array[i,j] = uniform_map[bin_to_decimal(sum_)] #If the number of jumps is less than or equal to 2, the decimal value corresponding to the binary sequence is the LBP value in the center of the neighborhood. There are only 58 possible values, but the maximum value can be 255, so the mapping is carried out here.\n",
    "            else:\n",
    "                revolve_array[i,j] = 58\n",
    "    return revolve_array\n",
    "def calc_sum(r):  # Gets the number of jumps in the binary of the value r\n",
    "    sum_ = 0\n",
    "    for i in range(0,len(r)-1):\n",
    "        if(r[i] != r[i+1]):\n",
    "            sum_ += 1\n",
    "    return sum_\n",
    "\n",
    "def show_uniform_hist(img_array):\n",
    "    show_hist(img_array, [60], [0, 60])\n",
    "    \n",
    "    \n",
    "def show_hist(img_array,im_bins,im_range):\n",
    "    hist = cv2.calcHist([img_array], [0], None, im_bins, im_range)\n",
    "    hist = cv2.normalize(hist, hist).flatten()\n",
    "    plt.plot(hist, color='r')\n",
    "    plt.xlim(im_range)\n",
    "    plt.show()\n",
    "    \n",
    "#Convert Array(text) to Image(matrix)\n",
    "def convert_array(text):\n",
    "    out = io.BytesIO(text)\n",
    "    out.seek(0)\n",
    "    return np.load(out)\n",
    "\n",
    "# Converts TEXT to np.array when selecting\n",
    "sqlite3.register_converter(\"array\", convert_array)\n",
    "\n",
    "train_conn = sqlite3.connect('Train_Images.db')\n",
    "train_connection = train_conn.cursor()\n",
    "\n",
    "train_connection.execute(\"SELECT *,oid FROM train_images\")\n",
    "#fetchall fetchmany(any number) fetchone\n",
    "records = train_connection.fetchall()\n",
    "#loop thru results\n",
    "\n",
    "for record in records:\n",
    "    row = int(re.findall(r'\\b\\d+\\b',record[2])[0])\n",
    "    column = int(re.findall(r'\\b\\d+\\b',record[2])[1])\n",
    "\n",
    "    #image = record[4]\n",
    "    #B = np.reshape(image, (row, column))\n",
    "    image = str((record[0][0])) + (record[1])\n",
    "    #print(image)\n",
    "    #im = np.reshape(image, (row, column))\n",
    "    #cv2.imshow(image)\n",
    "    #gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    #uniform_array = lbp_uniform(gray)\n",
    "    #show_uniform_hist(uniform_array)\n",
    "    #plt.imshow(uniform_array,cmap='Greys_r')\n",
    "    #plt.show()\n",
    "    train_image = record[6]\n",
    "    out = io.BytesIO(train_image)\n",
    "    out.seek(0)\n",
    "    img = np.load(out)\n",
    "    img = img.flatten()\n",
    "    print(len(img))\n",
    "    \n",
    "train_conn.commit()\n",
    "train_conn.close()\n",
    "\n",
    "train_images = []\n",
    "train_folder_selected = 'D:/Essential Things/Work/Thesis/Files/New folder'\n",
    "data_files = [(x[0], x[2]) for x in os.walk(train_folder_selected)]\n",
    "i = 0\n",
    "for filename in os.listdir(train_folder_selected):\n",
    "    if os.path.splitext(os.path.basename(data_files[0][1][i]))[1] == '.pgm':\n",
    "        img = cv2.imread(os.path.join(train_folder_selected,filename))\n",
    "        if img is not None:\n",
    "            train_images.append(img)\n",
    "    else:\n",
    "        img = cv2.imread(os.path.join(train_folder_selected,filename),cv2.IMREAD_UNCHANGED)\n",
    "        if img is not None:\n",
    "            train_images.append(img)\n",
    "    \n",
    "    #print(train_images[0])\n",
    "    i += 1\n",
    "    \n",
    "#gray = cv2.cvtColor(train_images[1], cv2.COLOR_BGR2GRAY)\n",
    "#uniform_array = lbp_uniform(gray)\n",
    "#show_uniform_hist(uniform_array)\n",
    "#plt.imshow(uniform_array,cmap='Greys_r')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923d33dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = cv2.imread('D:/Essential Things/Work/Thesis/Files/New folder/1.1.jpg')\n",
    "cv2.imshow('image window', image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f69da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "import io\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def adapt_array(arr):\n",
    "    out = io.BytesIO()\n",
    "    np.save(out, arr)\n",
    "    out.seek(0)\n",
    "    return sqlite3.Binary(out.read())\n",
    "\n",
    "def convert_array(text):\n",
    "    out = io.BytesIO(text)\n",
    "    out.seek(0)\n",
    "    return np.load(out)\n",
    "\n",
    "\n",
    "# Converts np.array to TEXT when inserting\n",
    "sqlite3.register_adapter(np.ndarray, adapt_array)\n",
    "\n",
    "# Converts TEXT to np.array when selecting\n",
    "sqlite3.register_converter(\"array\", convert_array)\n",
    "\n",
    "train_conn = sqlite3.connect(\"test.db\", detect_types=sqlite3.PARSE_DECLTYPES)\n",
    "train_connection = train_conn.cursor()\n",
    "\n",
    "#train_connection.execute(\"create table test (arr array)\")\n",
    "\n",
    "train_folder_selected = 'D:/Essential Things/Work/Thesis/Files/New folder'\n",
    "#get file names and format of each image\n",
    "data_files = [(x[0], x[2]) for x in os.walk(train_folder_selected)]\n",
    "    \n",
    "#read images from directory\n",
    "train_images = []\n",
    "i = 0\n",
    "for filename in os.listdir(train_folder_selected):\n",
    "    \n",
    "    #check if image format is .pgm read correctly or gray\n",
    "    if (os.path.splitext(os.path.basename(data_files[0][1][i]))[1] == '.pgm'):\n",
    "        img = cv2.imread(os.path.join(train_folder_selected,filename))        \n",
    "        if img is not None:\n",
    "            train_images.append(img)\n",
    "    else:\n",
    "        img = cv2.imread(os.path.join(train_folder_selected,filename),cv2.IMREAD_UNCHANGED)     \n",
    "        if img is not None:\n",
    "            train_images.append(img)\n",
    "            \n",
    "    train_connection.execute(\"insert into test (arr) values (?)\", (train_images[i], ))\n",
    "\n",
    "#commit and close connection from database\n",
    "train_conn.commit()\n",
    "train_conn.close()\n",
    "\n",
    "train_conn = sqlite3.connect('test.db')\n",
    "train_connection = train_conn.cursor()\n",
    "\n",
    "train_connection.execute(\"select arr from test\")\n",
    "#fetchall fetchmany(any number) fetchone\n",
    "records = train_connection.fetchall()\n",
    "\n",
    "#loop thru results\n",
    "for record in records:\n",
    "    train_image = record[0]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdf965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "import PIL.Image\n",
    "import base64\n",
    "\n",
    "def adapt_array(arr):\n",
    "    out = io.BytesIO()\n",
    "    np.save(out, arr)\n",
    "    out.seek(0)\n",
    "    return sqlite3.Binary(out.read())\n",
    "\n",
    "def convert_array(text):\n",
    "    out = io.BytesIO(text)\n",
    "    out.seek(0)\n",
    "    return np.load(out)\n",
    "\n",
    "\n",
    "# Converts np.array to TEXT when inserting\n",
    "sqlite3.register_adapter(np.ndarray, adapt_array)\n",
    "\n",
    "# Converts TEXT to np.array when selecting\n",
    "sqlite3.register_converter(\"array\", convert_array)\n",
    "\n",
    "train_conn = sqlite3.connect('Train_Images.db',  detect_types=sqlite3.PARSE_DECLTYPES)\n",
    "train_connection = train_conn.cursor()\n",
    "\n",
    "train_folder_selected = 'D:/Essential Things/Work/Thesis/Files/New folder'\n",
    "#get file names and format of each image\n",
    "data_files = [(x[0], x[2]) for x in os.walk(train_folder_selected)]\n",
    "    \n",
    "#read images from directory\n",
    "train_images = []\n",
    "i = 0\n",
    "for filename in os.listdir(train_folder_selected):\n",
    "    \n",
    "    #check if image format is .pgm read correctly or gray\n",
    "    if (os.path.splitext(os.path.basename(data_files[0][1][i]))[1] == '.pgm'):\n",
    "        img = cv2.imread(os.path.join(train_folder_selected,filename))        \n",
    "        if img is not None:\n",
    "            train_images.append(img)\n",
    "    else:\n",
    "        img = cv2.imread(os.path.join(train_folder_selected,filename),cv2.IMREAD_UNCHANGED)     \n",
    "        if img is not None:\n",
    "            train_images.append(img)\n",
    "            \n",
    "    train_connection.execute(\"INSERT INTO train_images VALUES (:name, :format, :size, :address, :file, :img_gray, :lbp_array)\",\n",
    "                     {\n",
    "                         'name':str(os.path.splitext(os.path.basename(data_files[0][1][i]))[0]),\n",
    "                         'format':str(os.path.splitext(os.path.basename(data_files[0][1][i]))[1]),\n",
    "                         'size':1,\n",
    "                         'address':str(data_files[0][0]),\n",
    "                         'file':(train_images[i]),\n",
    "                         'img_gray':1,\n",
    "                         'lbp_array':0\n",
    "                     })\n",
    "    i += 1\n",
    "    \n",
    "#commit and close connection from database\n",
    "train_conn.commit()\n",
    "train_conn.close()\n",
    "\n",
    "train_conn = sqlite3.connect('Train_Images.db')\n",
    "train_connection = train_conn.cursor()\n",
    "train_connection.execute(\"SELECT * FROM train_images\")\n",
    "#fetchall fetchmany(any number) fetchone\n",
    "records = train_connection.fetchall()\n",
    "\n",
    "#loop thru results\n",
    "for record in records:\n",
    "    train_image = record[4]\n",
    "    print(train_image[0:4735])\n",
    "train_conn.commit()\n",
    "train_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f44b688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import sqlite3\n",
    "import io\n",
    "\n",
    "train_conn = sqlite3.connect('Test_Images.db')\n",
    "train_connection = train_conn.cursor()\n",
    "train_connection.execute(\"SELECT * FROM test_images\")\n",
    "#fetchall fetchmany(any number) fetchone\n",
    "records = train_connection.fetchall()\n",
    "#loop thru results\n",
    "for record in records:\n",
    "    train_image = record[6]\n",
    "    out = io.BytesIO(train_image)\n",
    "    out.seek(0)\n",
    "    img = np.load(out)\n",
    "    plt.imshow(img, interpolation='nearest')\n",
    "    plt.show()\n",
    "    print(img.shape)\n",
    "train_conn.commit()\n",
    "train_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3171bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = record[6]\n",
    "print(train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1923358",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(12).reshape(2,6)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95e5fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sqlite3\n",
    "import os\n",
    "train_conn = sqlite3.connect('train_images.db')\n",
    "train_connection = train_conn.cursor()\n",
    "\n",
    "'''\n",
    "train_connection.execute(\"\"\"CREATE TABLE train_images (\n",
    "        name text, \n",
    "        format text,\n",
    "        size integer,\n",
    "        address text,\n",
    "        file array,\n",
    "        img_gray array,\n",
    "        lbp_array array\n",
    "        )\"\"\")\n",
    "'''\n",
    "\n",
    "train_folder_selected = 'D:/Essential Things/Work/Thesis/Files/New folder'\n",
    "#get file names and format of each image\n",
    "data_files = [(x[0], x[2]) for x in os.walk(train_folder_selected)]\n",
    "    \n",
    "#read images from directory\n",
    "train_images = []\n",
    "i = 0\n",
    "for filename in os.listdir(train_folder_selected):\n",
    "    \n",
    "    #check if image format is .pgm read correctly or gray\n",
    "    if (os.path.splitext(os.path.basename(data_files[0][1][i]))[1] == '.pgm'):\n",
    "        img = cv2.imread(os.path.join(train_folder_selected,filename))        \n",
    "        if img is not None:\n",
    "            train_images.append(img)\n",
    "    else:\n",
    "        img = cv2.imread(os.path.join(train_folder_selected,filename),cv2.IMREAD_UNCHANGED)     \n",
    "        if img is not None:\n",
    "            train_images.append(img)\n",
    "            \n",
    "    train_connection.execute(\"INSERT INTO train_images VALUES (:name, :format, :size, :address, :file, :img_gray, :lbp_array)\",\n",
    "                     {\n",
    "                         'name':str(os.path.splitext(os.path.basename(data_files[0][1][i]))[0]),\n",
    "                         'format':str(os.path.splitext(os.path.basename(data_files[0][1][i]))[1]),\n",
    "                         'size':1,\n",
    "                         'address':str(data_files[0][0]),\n",
    "                         'file':(train_images[i]),\n",
    "                         'img_gray':1,\n",
    "                         'lbp_array':0\n",
    "                     })\n",
    "    print(train_images[i])\n",
    "    i += 1\n",
    "\n",
    "train_conn.commit()\n",
    "train_conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8b8485",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_conn = sqlite3.connect('train_images.db')\n",
    "train_connection = train_conn.cursor()\n",
    "\n",
    "file = train_connection.execute('select file from train_images where oid=?', (33,)).fetchone()\n",
    "print(type(file[0]))\n",
    "#img = cv2.imread(file,cv2.IMREAD_UNCHANGED)\n",
    "#cv2.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8a7433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from PIL import ImageTk, Image\n",
    "from tkinter import filedialog\n",
    "import numpy as np\n",
    "import tksheet\n",
    "import sqlite3\n",
    "import cv2\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "\n",
    "def recognize():\n",
    "    #create connection in database\n",
    "    train_conn = sqlite3.connect('Train_Images.db', detect_types=sqlite3.PARSE_DECLTYPES)\n",
    "    train_connection = train_conn.cursor()\n",
    "    train_connection.execute(\"SELECT *,oid FROM train_images\")\n",
    "    #fetchall fetchmany(any number) fetchone\n",
    "    train_records = train_connection.fetchall()\n",
    "\n",
    "    #create connection in database\n",
    "    test_conn = sqlite3.connect('Test_Images.db', detect_types=sqlite3.PARSE_DECLTYPES)\n",
    "    test_connection = test_conn.cursor()\n",
    "    test_connection.execute(\"SELECT *,oid FROM test_images\")\n",
    "    #fetchall fetchmany(any number) fetchone\n",
    "    test_records = test_connection.fetchall()\n",
    "    \n",
    "    #loop thru results\n",
    "    recognized = 0\n",
    "    index = 0\n",
    "    recognized_index = 0\n",
    "    for test_record in test_records:\n",
    "        testrow = int(re.findall(r'\\b\\d+\\b',test_record[2])[0])\n",
    "        testcolumn = int(re.findall(r'\\b\\d+\\b',test_record[2])[1])\n",
    "        testImageIdentities = str((test_record[0][0])) + (test_record[1])\n",
    "        testcase = test_record[6]\n",
    "        testout = io.BytesIO(testcase)\n",
    "        testout.seek(0)\n",
    "        test_case = np.load(testout)\n",
    "        test_image = test_case.flatten()\n",
    "\n",
    "        differences = []\n",
    "        trainImageIdentities = []\n",
    "        for train_record in train_records:\n",
    "            trainrow = int(re.findall(r'\\b\\d+\\b',train_record[2])[0])\n",
    "            traincolumn = int(re.findall(r'\\b\\d+\\b',train_record[2])[1])\n",
    "            trainImageIdentitie = str((train_record[0][0])) + (train_record[1])\n",
    "            trainImageIdentities.append(trainImageIdentitie)\n",
    "            traincase = (train_record[6])\n",
    "            trainout = io.BytesIO(traincase)\n",
    "            trainout.seek(0)\n",
    "            train_case = np.load(trainout)\n",
    "            train_image = train_case.flatten()\n",
    "\n",
    "            if len(train_image) == len(test_image):\n",
    "                diff = abs(train_image - test_image)\n",
    "            if len(train_image) > len(test_image):\n",
    "                test_case = np.pad(test_case, ((0,train_case.shape[0]-test_case.shape[0]),(0,train_case.shape[1]-test_case.shape[1])), mode='constant', constant_values=0)\n",
    "                test_image = test_case.flatten()\n",
    "                diff = abs(train_image - test_image)\n",
    "            if len(train_image) < len(test_image):\n",
    "                train_case = np.pad(train_case, ((0,test_case.shape[0]-train_case.shape[0]),(0,test_case.shape[1]-train_case.shape[1])), mode='constant', constant_values=0)\n",
    "                train_image = train_case.flatten()\n",
    "                diff = abs(train_image - test_image)\n",
    "              \n",
    "            sum1 = 0\n",
    "            sum1 = np.sum(diff)\n",
    "            differences.append(sum1)\n",
    "        recognized_index = differences.index(min(differences))\n",
    "        if testImageIdentities == trainImageIdentities[recognized_index]:\n",
    "            recognized = recognized + 1;\n",
    "        index += 1\n",
    "    identification_rate = (recognized / index) * 100;\n",
    "    print(identification_rate)\n",
    "    #commit and close connection from database\n",
    "    train_conn.commit()\n",
    "    train_conn.close()\n",
    "    \n",
    "    #commit and close connection from database\n",
    "    test_conn.commit()\n",
    "    test_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9755575",
   "metadata": {},
   "outputs": [],
   "source": [
    "recognize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f9d4af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from PIL import ImageTk, Image\n",
    "from tkinter import filedialog\n",
    "import numpy as np\n",
    "import tksheet\n",
    "import sqlite3\n",
    "import cv2\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "\n",
    "def recognize_sift():\n",
    "    #create connection in database\n",
    "    train_conn = sqlite3.connect('Train_Images.db', detect_types=sqlite3.PARSE_DECLTYPES)\n",
    "    train_connection = train_conn.cursor()\n",
    "    train_connection.execute(\"SELECT *,oid FROM train_images\")\n",
    "    #fetchall fetchmany(any number) fetchone\n",
    "    train_records = train_connection.fetchall()\n",
    "\n",
    "    #create connection in database\n",
    "    test_conn = sqlite3.connect('Test_Images.db', detect_types=sqlite3.PARSE_DECLTYPES)\n",
    "    test_connection = test_conn.cursor()\n",
    "    test_connection.execute(\"SELECT *,oid FROM test_images\")\n",
    "    #fetchall fetchmany(any number) fetchone\n",
    "    test_records = test_connection.fetchall()\n",
    "\n",
    "    # Flann Based Matcher\n",
    "    index_param = dict(algorithm=0, trees=5)\n",
    "    search_param = dict()\n",
    "    flann = cv2.FlannBasedMatcher(index_param, search_param)\n",
    "    \n",
    "    recognized = 0\n",
    "    index = 0\n",
    "    # Check the similarities between the images\n",
    "    for test_record in test_records:\n",
    "        kp2 = test_record[7]\n",
    "        descase2 = (test_record[8])\n",
    "        desout2 = io.BytesIO(descase2)\n",
    "        desout2.seek(0)\n",
    "        des2 = np.load(desout2)        \n",
    "        testImageIdentities = str((test_record[0][0])) + (test_record[1])\n",
    "        # Math result container\n",
    "        results = []\n",
    "        trainImageIdentities = []\n",
    "        # for all the train Images match function should be called\n",
    "        for train_record in train_records:\n",
    "            # Getting the current train image details\n",
    "            kp1 = train_record[7]\n",
    "            descase1 = (train_record[8])\n",
    "            desout1 = io.BytesIO(descase1)\n",
    "            desout1.seek(0)\n",
    "            des1 = np.load(desout1)\n",
    "            trainImageIdentitie = str((train_record[0][0])) + (train_record[1])\n",
    "            trainImageIdentities.append(trainImageIdentitie)\n",
    "            # check to see if there are enough key points for the matcher\n",
    "            if (kp1)>=2 and (kp2)>=2:\n",
    "                # calling the flann based match function\n",
    "                matches = flann.knnMatch(des1, des2, k=2)\n",
    "                good_points = []\n",
    "                for m, n in matches:\n",
    "                    if m.distance < 0.5 * n.distance:\n",
    "                        good_points.append(m)\n",
    "                # getting the maximum number of keypoints\n",
    "                number_keypoints = 0\n",
    "                if (kp1) < (kp2):\n",
    "                    number_keypoints = (kp1)\n",
    "                else:\n",
    "                    number_keypoints = (kp2)\n",
    "                # the results of the match\n",
    "                res = len(good_points) / (kp2) * 100\n",
    "                results.append(res)\n",
    "            else:\n",
    "                results.append(0)\n",
    "        # finding the maximum matching result\n",
    "        maxx = 0\n",
    "        maxIndex = 0\n",
    "        for r in range(len(results)):\n",
    "            if results[r] > maxx:\n",
    "                maxx = results[r]\n",
    "                maxIndex = r\n",
    "                    \n",
    "        # Checking the authenticity of the matched result\n",
    "        if testImageIdentities == trainImageIdentities[maxIndex]:\n",
    "            recognized += 1\n",
    "        index += 1\n",
    "        \n",
    "    identification_rate = (recognized / index) * 100;\n",
    "    print(identification_rate)\n",
    "    #commit and close connection from database\n",
    "    train_conn.commit()\n",
    "    train_conn.close()\n",
    "    \n",
    "    #commit and close connection from database\n",
    "    test_conn.commit()\n",
    "    test_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84e8fe41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.76119402985076\n"
     ]
    }
   ],
   "source": [
    "recognize_sift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0c0e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "print (\"OpenCV version :  {0}\".format(cv2.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd2a830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "Kp_Des = []\n",
    "# Calculating images keypoints\n",
    "img = cv2.imread('D:/Essential Things/Work/Thesis/Files/New folder/New folder/1.1.jpg',cv2.IMREAD_UNCHANGED)\n",
    "img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "kp, des = sift.detectAndCompute(img, None)\n",
    "kp = len(kp)\n",
    "print(type(kp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "913398ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "from PIL import ImageTk, Image\n",
    "from tkinter import filedialog\n",
    "import numpy as np\n",
    "import tksheet\n",
    "import sqlite3\n",
    "import cv2\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "\n",
    "#create connection in database\n",
    "train_conn = sqlite3.connect('Train_Images.db', detect_types=sqlite3.PARSE_DECLTYPES)\n",
    "train_connection = train_conn.cursor()\n",
    "train_connection.execute(\"SELECT *,oid FROM train_images\")\n",
    "#fetchall fetchmany(any number) fetchone\n",
    "train_records = train_connection.fetchall()\n",
    "\n",
    "#create connection in database\n",
    "test_conn = sqlite3.connect('Test_Images.db', detect_types=sqlite3.PARSE_DECLTYPES)\n",
    "test_connection = test_conn.cursor()\n",
    "test_connection.execute(\"SELECT *,oid FROM test_images\")\n",
    "#fetchall fetchmany(any number) fetchone\n",
    "test_records = test_connection.fetchall()\n",
    "\n",
    "# Flann Based Matcher\n",
    "index_param = dict(algorithm=0, trees=5)\n",
    "search_param = dict()\n",
    "flann = cv2.FlannBasedMatcher(index_param, search_param)\n",
    "\n",
    "recognized = 0\n",
    "index = 0\n",
    "# Check the similarities between the images\n",
    "for test_record in test_records:\n",
    "    kp2 = test_record[7]\n",
    "    descase2 = (test_record[8])\n",
    "    desout2 = io.BytesIO(descase2)\n",
    "    desout2.seek(0)\n",
    "    des2 = np.load(desout2)        \n",
    "    testImageIdentities = str((test_record[0][0])) + (test_record[1])\n",
    "    # Math result container\n",
    "    results = []\n",
    "    trainImageIdentities = []\n",
    "    # for all the train Images match function should be called\n",
    "    for train_record in train_records:\n",
    "        # Getting the current train image details\n",
    "        kp1 = train_record[7]\n",
    "        descase1 = (train_record[8])\n",
    "        desout1 = io.BytesIO(descase1)\n",
    "        desout1.seek(0)\n",
    "        des1 = np.load(desout1)\n",
    "        trainImageIdentitie = str((train_record[0][0])) + (train_record[1])\n",
    "        trainImageIdentities.append(trainImageIdentitie)\n",
    "        # check to see if there are enough key points for the matcher\n",
    "        if (kp1)>=2 and (kp2)>=2:\n",
    "            # calling the flann based match function\n",
    "            matches = flann.knnMatch(des1, des2, k=2)\n",
    "            good_points = []\n",
    "            for m, n in matches:\n",
    "                if m.distance < 0.5 * n.distance:\n",
    "                    good_points.append(m)\n",
    "            # getting the maximum number of keypoints\n",
    "            number_keypoints = 0\n",
    "            if (kp1) < (kp2):\n",
    "                number_keypoints = (kp1)\n",
    "            else:\n",
    "                number_keypoints = (kp2)\n",
    "            # the results of the match\n",
    "            res = len(good_points) / (kp2) * 100\n",
    "            results.append(res)\n",
    "        else:\n",
    "            results.append(0)\n",
    "    # finding the maximum matching result\n",
    "    maxx = 0\n",
    "    maxIndex = 0\n",
    "    for r in range(len(results)):\n",
    "        if results[r] > maxx:\n",
    "            maxx = results[r]\n",
    "            maxIndex = r\n",
    "    # Checking the authenticity of the matched result\n",
    "    if testImageIdentities == trainImageIdentities[maxIndex]:\n",
    "        recognized += 1\n",
    "    index += 1\n",
    "\n",
    "identification_rate = (recognized / index) * 100;\n",
    "print(identification_rate)\n",
    "#commit and close connection from database\n",
    "train_conn.commit()\n",
    "train_conn.close()\n",
    "\n",
    "#commit and close connection from database\n",
    "test_conn.commit()\n",
    "test_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875d40f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
